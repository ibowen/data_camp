#################A HBase implementation of LoadFunc and StoreFunc. Below is an example showing how to load data from HBase:raw = LOAD 'hbase://SampleTable'       USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(       'info:first_name info:last_name friends:* info:*', '-loadKey true -limit 5')       AS (id:bytearray, first_name:chararray, last_name:chararray, friends_map:map[], info_map:map[]);       This example loads data redundantly from the info column family just to illustrate usage. Note that the row key is inserted first in the result schema. To load only column names that start with a given prefix, specify the column name with a trailing '*'. For example passing friends:bob_* to the constructor in the above example would cause only columns that start with bob_ to be loaded.Note that when using a prefix like friends:bob_*, explicit HBase filters are set for all columns and prefixes specified. Querying HBase with many filters can cause performance degredation. This is typically seen when mixing one or more prefixed descriptors with a large list of columns. In that case better perfomance will be seen by either loading the entire family via friends:* or by specifying explicit column descriptor names.Below is an example showing how to store data into HBase:copy = STORE raw INTO 'hbase://SampleTableCopy'       USING org.apache.pig.backend.hadoop.hbase.HBaseStorage(       'info:first_name info:last_name friends:* info:*'); * Note that STORE will expect the first value in the tuple to be the row key. * Scalars values need to map to an explicit column descriptor and maps need to map to a column family name. * In the above examples, the friends column family data from SampleTable will be written to a buddies column family in the SampleTableCopy table.https://pig.apache.org/docs/r0.10.0/api/org/apache/pig/backend/hadoop/hbase/HBaseStorage.html################## must put jar into hdfs contextREGISTER 'hdfs://master1.internal.datalaus.net:8020/user/1604bowen/lib/piggybank-0.15.0.jar';REGISTER 'hdfs://master1.internal.datalaus.net:8020/user/1604bowen/lib/elephant-bird-hadoop-compat-4.14-RC2.jar';REGISTER 'hdfs://master1.internal.datalaus.net:8020/user/1604bowen/lib/elephant-bird-core-4.14-RC2.jar';REGISTER 'hdfs://master1.internal.datalaus.net:8020/user/1604bowen/lib/elephant-bird-pig-4.14-RC2.jar';REGISTER 'hdfs://master1.internal.datalaus.net:8020/user/1604bowen/lib/json-simple-1.1.1.jar';############ step 0 create tablescreate 'yelp_business_fromPig_bowen', {NAME => 'profile'}, {NAME => 'review'}create 'yelp_checkin_fromPig_bowen', {NAME => 'business'}, {NAME => 'checkin_info'}create 'yelp_user_fromPig_bowen', {NAME => 'user'}, {NAME => 'review'}create 'yelp_review_fromPig_bowen', {NAME => 'user'}, {NAME => 'business'}, {NAME => 'review'}enable 'yelp_business_fromPig_bowen'enable 'yelp_checkin_fromPig_bowen'enable 'yelp_user_fromPig_bowen'enable 'yelp_review_fromPig_bowen'########### step 1 load data into pig-- businessbusiness = load '/user/1604bowen/yelp/business_json/yelp_training_set_business.json' using JsonLoader('business_id:chararray,	full_address:chararray,	open:chararray,	categories:{t:(i:chararray)},	city:chararray,	review_count:int,	name:chararray,	neighborhoods:[(chararray)],	longitude:chararray,	state:chararray,	stars:float,	latitude:chararray,	type:chararray');	business_category_neighbor = foreach business generate categories, neighborhoods;business_sample = limit business_category_neighbor 10;dump business_sample;-- checkincheckin = LOAD '/user/1604bowen/yelp/checkin_json/yelp_training_set_checkin.json' USING com.twitter.elephantbird.pig.load.JsonLoader('-nestedLoad') AS (json:map[]);checkin_row = FOREACH checkin GENERATE (chararray)json#'business_id' As business_id, (chararray)json#'type' As type, (map[])json#'checkin_info' As checkin_info;checkin_sample = limit checkin_row 10;DUMP checkin_sample;-- useruser = load '/user/1604bowen/yelp/user_json/yelp_training_set_user.json' using JsonLoader('votes:(funny:chararray,useful:chararray,cool:chararray),  	user_id:chararray,  	name:chararray,  	average_stars:float,  	review_count:chararray,  	type:chararray');	user_row = foreach user generate user_id, name, average_stars, review_count, type, votes.useful as useful, votes.funny as funny, votes.cool as cool;user_row_sample = limit user_row 10;dump user_row_sample;-- reviewreview = load '/user/1604bowen/yelp/review_json/yelp_training_set_review.json' using JsonLoader('votes:(funny:chararray,useful:chararray,cool:chararray),  	user_id:chararray,  	review_id:chararray,  	stars:int,  	date:datetime,  	text:chararray,  	type:chararray,  	business_id:chararray');  		review_row= foreach review generate user_id, business_id, review_id, date, stars, type, text, votes.useful as useful, votes.funny as funny, votes.cool as cool;review_row_sample = limit review_row 10;dump review_row_sample;############## step 2 load data into hbase-- businessSTORE business INTO 'hbase://yelp_business_fromPig_bowen' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('profile:business_id,profile:full_address,profile:open,profile:categories,profile:city,review:review_count,profile:name,profile:neighborhoods,profile:longitude,profile:state,review:stars,profile:latitude,profile:type');scan 'yelp_business_fromPig_bowen', {'LIMIT' => 5}-- checkinSTORE checkin_row INTO 'hbase://yelp_checkin_fromPig_bowen' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('business:business_id,business:type,checkin_info:*');scan 'yelp_checkin_fromPig_bowen', {'LIMIT' => 5}-- userSTORE user_row INTO 'hbase://yelp_user_fromPig_bowen' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('user:user_id,user:name,user:type,review:average_stars,review:review_count,review:useful,review:funny,review:cool');scan 'yelp_user_fromPig_bowen', {'LIMIT' => 5}-- reviewSTORE review_row INTO 'hbase://yelp_review_fromPig_bowen' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('user:user_id,business:business_id,review:review_id,review:date,review:type,review:stars,review:text,review:useful,review:funny,review:cool');scan 'yelp_review_fromPig_bowen', {'LIMIT' => 5}