{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL of raw data into clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228017\n"
     ]
    }
   ],
   "source": [
    "with open('./data/LAPD_Crime_and_Collision_Raw_Data.json') as crime_json:    \n",
    "    crime_json = json.load(crime_json)\n",
    "    crime_data = crime_json['data']\n",
    "    print len(crime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for crime_row in crime_data:\n",
    "    crime_dict = {}\n",
    "    crime_dict['date_occ'] = crime_row[10].strip() if crime_row[10] is not None else None\n",
    "    crime_dict['time_occ'] = crime_row[11].strip() if crime_row[11] is not None else None\n",
    "    crime_dict['area'] = crime_row[12].strip() if crime_row[12] is not None else None\n",
    "    crime_dict['area_name'] = crime_row[13].strip() if crime_row[13] is not None else None\n",
    "    crime_dict['road'] = crime_row[14].strip() if crime_row[14] is not None else None\n",
    "    crime_dict['crime_code'] = crime_row[15].strip() if crime_row[15] is not None else None\n",
    "    crime_dict['crime_desc'] = crime_row[16].strip() if crime_row[16] is not None else None\n",
    "    crime_dict['location'] = re.sub(' +', '', crime_row[19].strip()) if crime_row[19] is not None else None\n",
    "    crime_dict['cross_street'] = crime_row[20].strip() if crime_row[20] is not None else None\n",
    "    crime_dict['cross_street'] = re.sub(' +', '', crime_dict['cross_street']) if crime_dict['cross_street'] is not None else None\n",
    "    crime_dict['latitude'] = crime_row[21][1].strip()\n",
    "    crime_dict['longitude'] = crime_row[21][2].strip()\n",
    "    with open('./data/lapd_clean_Data.json', 'a') as clean_data:\n",
    "        json.dump(crime_dict, clean_data)\n",
    "        clean_data.write(\"\\n\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime = sqlContext.read.json('./data/lapd_clean_Data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: string (nullable = true)\n",
      " |-- area_name: string (nullable = true)\n",
      " |-- crime_code: string (nullable = true)\n",
      " |-- crime_desc: string (nullable = true)\n",
      " |-- cross_street: string (nullable = true)\n",
      " |-- date_occ: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- road: string (nullable = true)\n",
      " |-- time_occ: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime.registerTempTable('crime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top areas with the most serious crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|  area_name|crime_count|\n",
      "+-----------+-----------+\n",
      "|77th Street|      15308|\n",
      "|  Southwest|      14733|\n",
      "|    Pacific|      12376|\n",
      "|N Hollywood|      12229|\n",
      "|  Southeast|      11399|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_script = 'SELECT area_name, COUNT(crime_code) AS crime_count FROM crime GROUP BY area_name ORDER BY crime_count DESC LIMIT 5'\n",
    "sqlContext.sql(sql_script).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top time with the most serious crime in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------+\n",
      "|           location|time_occ|crime_count|\n",
      "+-------------------+--------+-----------+\n",
      "|9300TOPANGACANYONBL|    1200|         49|\n",
      "|      15100RAYMERST|    2330|         30|\n",
      "|              6THST|    1900|         23|\n",
      "|     11800SHELDONST|    1600|         23|\n",
      "|              7THST|    2000|         19|\n",
      "+-------------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_script = 'SELECT location, time_occ, COUNT(crime_code) AS crime_count FROM crime GROUP BY location, time_occ ORDER BY crime_count DESC LIMIT 5'\n",
    "sqlContext.sql(sql_script).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top crime occurence within one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|time_occ|crime_count|\n",
      "+--------+-----------+\n",
      "|    1200|      10102|\n",
      "|    1800|       6242|\n",
      "|    2000|       5751|\n",
      "|    1900|       5531|\n",
      "|    2100|       5453|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_script = 'SELECT time_occ, COUNT(crime_code) AS crime_count FROM crime GROUP BY time_occ ORDER BY crime_count DESC LIMIT 5'\n",
    "sqlContext.sql(sql_script).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top crime types in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "| location|crime_code|crime_count|\n",
      "+---------+----------+-----------+\n",
      "|WESTERNAV|       997|        514|\n",
      "|VENTURABL|       997|        510|\n",
      "|VICTORYBL|       997|        438|\n",
      "|SHERMANWY|       997|        436|\n",
      "|VERMONTAV|       997|        428|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_script = 'SELECT location, crime_code, COUNT(*) AS crime_count FROM crime GROUP BY location, crime_code ORDER BY crime_count DESC LIMIT 5'\n",
    "sqlContext.sql(sql_script).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "ssc = StreamingContext(sc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discretized Streams\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count each word in each batch\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Print the first ten elements of each RDD generated in this DStream to the console\n",
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.start()             # Start the computation\n",
    "ssc.awaitTermination()  # Wait for the computation to terminate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
